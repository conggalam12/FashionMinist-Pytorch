{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uX_kHqO2Z7U",
        "outputId": "79e230c3-95ed-4487-c253-da5bd27a9f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16451562.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 305419.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5482573.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5658353.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print('  '.join(classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "umKgJL3z2h4h",
        "outputId": "f7640c76-8af8-4491-b852-3df464300567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dress  Shirt  T-shirt/top  Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class GarmentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GarmentClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GarmentClassifier()"
      ],
      "metadata": {
        "id": "NlPzZTOs2kSy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
        "# Represents the model's confidence in each of the 10 classes for a given input\n",
        "dummy_outputs = torch.rand(4, 10)\n",
        "# Represents the correct class among the 10 being tested\n",
        "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
        "\n",
        "print(dummy_outputs)\n",
        "print(dummy_labels)\n",
        "\n",
        "loss = loss_fn(dummy_outputs, dummy_labels)\n",
        "print('Total loss for this batch: {}'.format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f_VI9l92mmo",
        "outputId": "793226fc-741e-4e9a-8d23-d5e9ed8325c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8290, 0.0097, 0.1066, 0.2082, 0.8393, 0.3293, 0.4809, 0.6730, 0.8817,\n",
            "         0.5454],\n",
            "        [0.9266, 0.9767, 0.0374, 0.1878, 0.2573, 0.4574, 0.2278, 0.9410, 0.6032,\n",
            "         0.7105],\n",
            "        [0.8201, 0.6616, 0.7029, 0.6320, 0.0503, 0.3139, 0.1625, 0.7074, 0.4216,\n",
            "         0.6652],\n",
            "        [0.9790, 0.0837, 0.4545, 0.6756, 0.0250, 0.9951, 0.0507, 0.1010, 0.6684,\n",
            "         0.0726]])\n",
            "tensor([1, 5, 3, 7])\n",
            "Total loss for this batch: 2.5392045974731445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "Ta8Re4BG2p_I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "J5gmSSuu2ttp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "    # We don't need gradients on to do reporting\n",
        "    model.train(False)\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    for i, vdata in enumerate(validation_loader):\n",
        "        vinputs, vlabels = vdata\n",
        "        voutputs = model(vinputs)\n",
        "        vloss = loss_fn(voutputs, vlabels)\n",
        "        running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA4gV9BR2vla",
        "outputId": "df869c16-a2c3-44f9-bdba-f83a86cc53f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 1.7336270167976617\n",
            "  batch 2000 loss: 0.8268158037494868\n",
            "  batch 3000 loss: 0.6973681762013585\n",
            "  batch 4000 loss: 0.6337526922887191\n",
            "  batch 5000 loss: 0.5982711970000528\n",
            "  batch 6000 loss: 0.5511261123166769\n",
            "  batch 7000 loss: 0.523133688764181\n",
            "  batch 8000 loss: 0.477607687223237\n",
            "  batch 9000 loss: 0.47875837938836774\n",
            "  batch 10000 loss: 0.48275917510595173\n",
            "  batch 11000 loss: 0.4501952094044536\n",
            "  batch 12000 loss: 0.44738978008390407\n",
            "  batch 13000 loss: 0.4481765945449588\n",
            "  batch 14000 loss: 0.43368433816015023\n",
            "  batch 15000 loss: 0.39497364222728354\n",
            "LOSS train 0.39497364222728354 valid 0.42465445399284363\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 0.4101819966604235\n",
            "  batch 2000 loss: 0.37963571429622245\n",
            "  batch 3000 loss: 0.3975325840630103\n",
            "  batch 4000 loss: 0.3917162713009166\n",
            "  batch 5000 loss: 0.37521913186435996\n",
            "  batch 6000 loss: 0.3788082196007017\n",
            "  batch 7000 loss: 0.3630820569524076\n",
            "  batch 8000 loss: 0.36614547691229926\n",
            "  batch 9000 loss: 0.3704246617240133\n",
            "  batch 10000 loss: 0.37143890883080893\n",
            "  batch 11000 loss: 0.3549181798453501\n",
            "  batch 12000 loss: 0.34010457611597666\n",
            "  batch 13000 loss: 0.36618144852423573\n",
            "  batch 14000 loss: 0.3613605178856524\n",
            "  batch 15000 loss: 0.3549860274535859\n",
            "LOSS train 0.3549860274535859 valid 0.375357061624527\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.3255457371190569\n",
            "  batch 2000 loss: 0.3546587802398717\n",
            "  batch 3000 loss: 0.30524846155684643\n",
            "  batch 4000 loss: 0.33327740590041505\n",
            "  batch 5000 loss: 0.3184080536778438\n",
            "  batch 6000 loss: 0.34087990119642925\n",
            "  batch 7000 loss: 0.31661931336419\n",
            "  batch 8000 loss: 0.3420706820485648\n",
            "  batch 9000 loss: 0.3238509276937257\n",
            "  batch 10000 loss: 0.3503158081196598\n",
            "  batch 11000 loss: 0.31651210740121316\n",
            "  batch 12000 loss: 0.3226585860266059\n",
            "  batch 13000 loss: 0.3267295062948251\n",
            "  batch 14000 loss: 0.31974455398494317\n",
            "  batch 15000 loss: 0.2982750187063648\n",
            "LOSS train 0.2982750187063648 valid 0.3395065367221832\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.28972583391315126\n",
            "  batch 2000 loss: 0.2945865646866732\n",
            "  batch 3000 loss: 0.30874228239041984\n",
            "  batch 4000 loss: 0.30205328812305376\n",
            "  batch 5000 loss: 0.28753032183956384\n",
            "  batch 6000 loss: 0.3058258065594855\n",
            "  batch 7000 loss: 0.31401961661010863\n",
            "  batch 8000 loss: 0.28688044850309236\n",
            "  batch 9000 loss: 0.29543575374133796\n",
            "  batch 10000 loss: 0.2993141414983984\n",
            "  batch 11000 loss: 0.2966007572429371\n",
            "  batch 12000 loss: 0.303756826485027\n",
            "  batch 13000 loss: 0.2798326622208115\n",
            "  batch 14000 loss: 0.29241473457978284\n",
            "  batch 15000 loss: 0.28233015317593524\n",
            "LOSS train 0.28233015317593524 valid 0.32409337162971497\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.26232668929403735\n",
            "  batch 2000 loss: 0.29555649868527323\n",
            "  batch 3000 loss: 0.2576163585653285\n",
            "  batch 4000 loss: 0.2673683442909096\n",
            "  batch 5000 loss: 0.2750155261458117\n",
            "  batch 6000 loss: 0.2919799013211991\n",
            "  batch 7000 loss: 0.287606370213417\n",
            "  batch 8000 loss: 0.27892202663312854\n",
            "  batch 9000 loss: 0.28083507770437427\n",
            "  batch 10000 loss: 0.28629261894136104\n",
            "  batch 11000 loss: 0.28372233904125826\n",
            "  batch 12000 loss: 0.26953708075107713\n",
            "  batch 13000 loss: 0.29694180882969523\n",
            "  batch 14000 loss: 0.2767041491286618\n",
            "  batch 15000 loss: 0.279057101566319\n",
            "LOSS train 0.279057101566319 valid 0.30302947759628296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'fashion.h5')"
      ],
      "metadata": {
        "id": "YSx_Fw8t2y6g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('fashion.h5'))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z0gcsUQ5Cn5",
        "outputId": "8c8404d5-2454-448f-c431-acbc4e812080"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GarmentClassifier(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}